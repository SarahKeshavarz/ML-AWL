{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d246856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\z086847\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# === PIP INSTALLS === installing the required tools\n",
    "!pip install lightgbm scikit-learn pandas numpy joblib matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edcda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS === importing the required tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc560fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 586, number of negative: 396\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1235\n",
      "[LightGBM] [Info] Number of data points in the train set: 982, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.596741 -> initscore=0.391906\n",
      "[LightGBM] [Info] Start training from score 0.391906\n",
      "[LightGBM] [Info] Number of positive: 581, number of negative: 401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1226\n",
      "[LightGBM] [Info] Number of data points in the train set: 982, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.591650 -> initscore=0.370789\n",
      "[LightGBM] [Info] Start training from score 0.370789\n",
      "[LightGBM] [Info] Number of positive: 586, number of negative: 397\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.596134 -> initscore=0.389384\n",
      "[LightGBM] [Info] Start training from score 0.389384\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.592065 -> initscore=0.372509\n",
      "[LightGBM] [Info] Start training from score 0.372509\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 387\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606307 -> initscore=0.431816\n",
      "[LightGBM] [Info] Start training from score 0.431816\n",
      "[LightGBM] [Info] Number of positive: 591, number of negative: 392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1220\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.601221 -> initscore=0.410554\n",
      "[LightGBM] [Info] Start training from score 0.410554\n",
      "[LightGBM] [Info] Number of positive: 598, number of negative: 385\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1226\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608342 -> initscore=0.440347\n",
      "[LightGBM] [Info] Start training from score 0.440347\n",
      "[LightGBM] [Info] Number of positive: 592, number of negative: 391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1224\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.602238 -> initscore=0.414799\n",
      "[LightGBM] [Info] Start training from score 0.414799\n",
      "[LightGBM] [Info] Number of positive: 581, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1227\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.591048 -> initscore=0.368299\n",
      "[LightGBM] [Info] Start training from score 0.368299\n",
      "[LightGBM] [Info] Number of positive: 584, number of negative: 399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1229\n",
      "[LightGBM] [Info] Number of data points in the train set: 983, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594100 -> initscore=0.380940\n",
      "[LightGBM] [Info] Start training from score 0.380940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\z086847\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1031: RuntimeWarning: overflow encountered in cast\n",
      "  arr = np.asarray(values, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40888\n",
      "[LightGBM] [Info] Number of data points in the train set: 19846, number of used features: 167\n",
      "[LightGBM] [Info] Start training from score 9184805961205522894245441633091846144.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40888\n",
      "[LightGBM] [Info] Number of data points in the train set: 19846, number of used features: 167\n",
      "[LightGBM] [Info] Start training from score 28.692181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40888\n",
      "[LightGBM] [Info] Number of data points in the train set: 19846, number of used features: 167\n",
      "[LightGBM] [Info] Start training from score 51.140522\n",
      "=== Top MOFs for AWH (Rule-based filtered) ===\n",
      "          Source        Di       Df       Dif  unit_cell_volume      rho  \\\n",
      "MOF_name                                                                   \n",
      "WASTUG       NaN  10.46560  7.25807  10.00791          5415.920  1.59439   \n",
      "BAWRUO       NaN   7.29901  5.68671   7.29901          3585.950  2.71918   \n",
      "GIFFAE       NaN   5.12876  3.25577   5.01955          2179.560  1.85543   \n",
      "NIGGAM       NaN   7.37601  4.62938   6.94847          1999.490  1.24921   \n",
      "NIGFUF       NaN   7.44488  4.63983   7.40016          2022.190  1.22204   \n",
      "...          ...       ...      ...       ...               ...      ...   \n",
      "MIVPAJ       NaN   3.21890  2.48956   3.21890          1077.890  2.35490   \n",
      "BETGAK       NaN   6.10951  4.21478   6.10951          2810.390  1.06153   \n",
      "ELILIV       NaN   4.97952  3.62473   4.97952           945.982  1.64354   \n",
      "SEYFAE       NaN   4.13987  3.30607   4.13987          1282.140  2.02738   \n",
      "ELIKUG       NaN   4.95561  3.72680   4.95492           959.652  1.57969   \n",
      "\n",
      "              VSA       GSA    VPOV      GPOV  ...           KHN  \\\n",
      "MOF_name                                       ...                 \n",
      "WASTUG    2144.56  1345.070  0.5873  0.368354  ...  9.110000e-07   \n",
      "BAWRUO    1822.82   670.358  0.4468  0.164314  ...  1.750000e-06   \n",
      "GIFFAE    2245.41  1210.180  0.4155  0.223937  ...  5.520000e-06   \n",
      "NIGGAM    2540.88  2033.980  0.6075  0.486307  ...  4.950000e-06   \n",
      "NIGFUF    2538.01  2076.870  0.6153  0.503502  ...  6.160000e-06   \n",
      "...           ...       ...     ...       ...  ...           ...   \n",
      "MIVPAJ       0.00     0.000  0.0615  0.026116  ...  1.620000e-08   \n",
      "BETGAK    2580.42  2430.860  0.5316  0.500787  ...  7.160000e-06   \n",
      "ELILIV    1489.87   906.503  0.3255  0.198048  ...  8.500000e-06   \n",
      "SEYFAE    1082.68   534.033  0.2415  0.119119  ...  2.930000e-06   \n",
      "ELIKUG    1487.89   941.888  0.3289  0.208205  ...  1.100000e-05   \n",
      "\n",
      "                   KHO    QstW20    QstW80    Wup20cm3    Wup80cm3  Wup20mmol  \\\n",
      "MOF_name                                                                        \n",
      "WASTUG    5.410000e-07 -52.22509 -58.62322  755.861960  862.364350  21.151108   \n",
      "BAWRUO    9.440000e-07 -59.25453 -50.58048  674.728891  705.397725  11.070609   \n",
      "GIFFAE    1.460000e-06 -60.39785 -66.80515  665.801072  701.193327  16.009272   \n",
      "NIGGAM    2.740000e-06 -62.91118 -59.39531  665.584865  742.105076  24.299669   \n",
      "NIGFUF    2.850000e-06 -58.78588 -59.45377  660.011280  746.925191  23.933019   \n",
      "...                ...       ...       ...         ...         ...        ...   \n",
      "MIVPAJ    5.310000e-08 -89.33155 -82.65289  391.532359  393.060267   7.899412   \n",
      "BETGAK    5.540000e-06 -48.86251 -47.34572  385.430338  599.275041  16.199395   \n",
      "ELILIV    5.360000e-06 -52.11344 -46.96128  382.427144  442.435960  10.381299   \n",
      "SEYFAE    2.050000e-06 -59.03621 -58.40742  380.914649  404.973793   8.382527   \n",
      "ELIKUG    5.620000e-06 -49.38863 -47.54343  380.440057  445.560489  10.744718   \n",
      "\n",
      "          Wup80mmol  Wselectivity  water_stability_prob  \n",
      "MOF_name                                                 \n",
      "WASTUG    24.131339  6.910000e+11              0.970602  \n",
      "BAWRUO    11.573807  1.720000e+07              0.979510  \n",
      "GIFFAE    16.860283  3.270000e+12              0.979355  \n",
      "NIGGAM    27.093326  1.990000e+12              0.934773  \n",
      "NIGFUF    27.084650  2.830000e+14              0.935949  \n",
      "...             ...           ...                   ...  \n",
      "MIVPAJ     7.930238  7.300000e+17              0.911257  \n",
      "BETGAK    25.187154  7.210000e+09              0.929486  \n",
      "ELILIV    12.010287  2.550000e+12              0.925537  \n",
      "SEYFAE     8.911980  3.370000e+08              0.984551  \n",
      "ELIKUG    12.583906  1.820000e+16              0.971482  \n",
      "\n",
      "[100 rows x 207 columns]\n"
     ]
    }
   ],
   "source": [
    "# === LOAD & PREPROCESS CLASSIFICATION DATA ===\n",
    "df_cls = pd.read_csv('Wstability-data.csv')\n",
    "df_cls['MOF_name'] = df_cls['MOF_name'].astype(str).str.strip()\n",
    "\n",
    "# Convert only numeric columns (exclude MOF_name and water_label)\n",
    "non_numeric_cols = ['MOF_name', 'water_label']\n",
    "numeric_cols = [col for col in df_cls.columns if col not in non_numeric_cols]\n",
    "\n",
    "df_cls[numeric_cols] = df_cls[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df_cls.replace(['#DIV/0!', '#NAME?', 'NaN', 'nan'], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaNs only in numeric columns with their mean\n",
    "df_cls[numeric_cols] = df_cls[numeric_cols].fillna(df_cls[numeric_cols].mean())\n",
    "\n",
    "# === SET FEATURES & TARGET ===\n",
    "rfa_features = [\n",
    "    'mc-I-3-all', 'D_lc-T-1-all', 'mc-Z-0-all', 'func-I-1-all', 'f-lig-I-3',\n",
    "    'func-I-0-all', 'D_lc-S-3-all', 'f-lig-I-0', 'KHW', 'D_mc-S-1-all'\n",
    "]\n",
    "\n",
    "y_cls = df_cls[\"water_label\"].astype(int).replace({1: 0, 2: 0, 3: 1, 4: 1})\n",
    "if y_cls.min() == 1:\n",
    "    y_cls -= 1\n",
    "\n",
    "# Handle missing classification features dynamically\n",
    "available_cls_features = [f for f in rfa_features if f in df_cls.columns]\n",
    "missing_cls_features = [f for f in rfa_features if f not in df_cls.columns]\n",
    "if missing_cls_features:\n",
    "    print(f\"⚠️ Warning: Missing features {missing_cls_features} will be skipped.\")\n",
    "\n",
    "X_cls = df_cls[available_cls_features].copy()\n",
    "X_cls.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_cls.fillna(X_cls.mean(), inplace=True)\n",
    "\n",
    "\n",
    "# === TRAIN CLASSIFIER ===\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model_cls = LGBMClassifier(random_state=42, n_jobs=-1)  # default params\n",
    "scaler_cls = StandardScaler()\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_cls):\n",
    "    X_train = scaler_cls.fit_transform(X_cls.iloc[train_idx])\n",
    "    y_train = y_cls.iloc[train_idx]\n",
    "    model_cls.fit(X_train, y_train)\n",
    "\n",
    "# Save trained classifier\n",
    "joblib.dump(model_cls, \"classifier_water_stability.pkl\")\n",
    "\n",
    "# === LOAD & PREPROCESS REGRESSION DATA ===\n",
    "df_reg = pd.read_csv('WUSdata-mod.csv')\n",
    "df_reg['MOF_name'] = df_reg['MOF_name'].astype(str).str.strip()\n",
    "df_reg.set_index('MOF_name', inplace=True)\n",
    "\n",
    "# EXACT preprocessing order for regression\n",
    "df_reg = df_reg.apply(pd.to_numeric, errors='coerce')\n",
    "df_reg.replace(['#DIV/0!', '#NAME?', 'NaN', 'nan'], np.nan, inplace=True)\n",
    "df_reg.fillna(df_reg.mean(), inplace=True)\n",
    "\n",
    "# === IDENTIFY KNOWN AND UNKNOWN STABILITY MOFs ===\n",
    "mofs_cls_set = set(df_cls['MOF_name'])\n",
    "mofs_reg_set = set(df_reg.index)\n",
    "\n",
    "known_mofs = list(mofs_reg_set & mofs_cls_set)\n",
    "unknown_mofs = list(mofs_reg_set - mofs_cls_set)\n",
    "\n",
    "df_known = df_reg.loc[known_mofs].copy()\n",
    "df_unknown = df_reg.loc[unknown_mofs].copy()\n",
    "\n",
    "# === PREDICT STABILITY ===\n",
    "available_reg_features = [f for f in rfa_features if f in df_known.columns]\n",
    "missing_reg_features = [f for f in rfa_features if f not in df_known.columns]\n",
    "if missing_reg_features:\n",
    "    print(f\"⚠️ Warning: Missing features {missing_reg_features} will be skipped.\")\n",
    "\n",
    "X_known = df_known[available_reg_features].copy()\n",
    "X_known = scaler_cls.transform(X_known)\n",
    "df_known['water_stability_prob'] = model_cls.predict_proba(X_known)[:, 1]\n",
    "\n",
    "X_unknown = df_unknown[available_reg_features].copy()\n",
    "X_unknown = scaler_cls.transform(X_unknown)\n",
    "df_unknown['water_stability_prob'] = model_cls.predict_proba(X_unknown)[:, 1]\n",
    "\n",
    "df_full = pd.concat([df_known, df_unknown])\n",
    "\n",
    "# === NUMERIC TARGET COLUMNS ===\n",
    "for target in ['Wselectivity', 'Wup20cm3', 'Wup80cm3']:\n",
    "    df_full[target] = pd.to_numeric(df_full[target], errors='coerce')\n",
    "\n",
    "# === DESCRIPTORS FOR REGRESSION ===\n",
    "descriptors_indices = [1, 195]\n",
    "headers = list(df_full.columns)\n",
    "descriptors = headers[min(descriptors_indices):max(descriptors_indices) + 1]\n",
    "\n",
    "# TRAIN AND SAVE REGRESSORS\n",
    "for target in ['Wselectivity', 'Wup20cm3', 'Wup80cm3']:\n",
    "    y = df_full[target]\n",
    "    X = df_full[[f for f in descriptors if f in df_full.columns]]\n",
    "    model = LGBMRegressor(\n",
    "        num_leaves=60,\n",
    "        n_estimators=400,\n",
    "        max_depth=-1,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    joblib.dump(model, f\"regressor_{target}.pkl\")\n",
    "\n",
    "# === APPLY STABILITY FILTER ===\n",
    "stable = df_full[df_full['water_stability_prob'] >= 0.9].dropna(\n",
    "    subset=['Wselectivity', 'Wup20cm3', 'Wup80cm3']\n",
    ")\n",
    "\n",
    "# === STATISTICAL FILTERING ===\n",
    "means = stable[['Wup20cm3', 'Wup80cm3']].mean()\n",
    "stds = stable[['Wup20cm3', 'Wup80cm3']].std()\n",
    "\n",
    "filtered = stable[\n",
    "    (stable['Wselectivity'] >= 1000) &\n",
    "    (stable['Wup20cm3'] >= means['Wup20cm3'] + stds['Wup20cm3']) &\n",
    "    (stable['Wup80cm3'] >= means['Wup80cm3'] + stds['Wup80cm3'])\n",
    "]\n",
    "\n",
    "# === OUTPUT SORTED TOP MOFs ===\n",
    "top_mofs = filtered.sort_values(by='Wup20cm3', ascending=False)\n",
    "print(\"=== Top MOFs for AWH (Rule-based filtered) ===\")\n",
    "print(top_mofs.head(100))\n",
    "\n",
    "final_features = [\n",
    "    'D_lc-S-3-all', 'D_lc-T-1-all', 'D_mc-S-1-all', 'Density-mcs',\n",
    "    'Df', 'Di', 'KHW', 'LCD-mcs', 'PLD-mcs', 'VF-mcs', 'VPOV',\n",
    "    'f-lig-I-0', 'f-lig-I-3', 'func-I-0-all', 'func-I-1-all',\n",
    "    'mc-I-3-all', 'mc-Z-0-all', 'mc-chi-2-all', 'mc-chi-3-all',\n",
    "    'unit_cell_volume', 'Wselectivity', 'Wup20cm3', 'Wup80cm3',\n",
    "    'water_stability_prob'\n",
    "]\n",
    "\n",
    "available_features = [f for f in final_features if f in top_mofs.columns]\n",
    "top_mofs[available_features].head(100).to_csv('top-100-MOFs-with-features.csv', index_label='MOF_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0af0403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: Missing classification features ['KHW'] will be skipped.\n",
      "Missing target values: ['Wselectivity', 'Wup20cm3', 'Wup80cm3']\n",
      "\n",
      "=== Input MOF Analysis ===\n",
      "              water_stability_prob    Wup20cm3    Wup80cm3  Wselectivity\n",
      "MOF_name                                                                \n",
      "AFOVIB                    0.964952   84.910965  367.605277  1.837068e+34\n",
      "AFOVOH                    0.643140   85.213964  429.894953  1.124565e+34\n",
      "AFOYOK                    0.152435   10.517955   -4.620797 -9.071337e+34\n",
      "AFUPEX                    0.902227  549.942071  689.938243 -8.408133e+34\n",
      "AGARUW                    0.815033  443.617217  508.937477  3.275685e+35\n",
      "AGAXOV                    0.870459    5.074611    3.053543 -1.345387e+35\n",
      "AGESIP                    0.738468    9.509624  170.698246 -2.749015e+35\n",
      "AGUWUV                    0.609928  278.316417  309.944763 -1.052961e+35\n",
      "AHINIP                    0.593315  131.495536  187.498999 -7.342718e+33\n",
      "AHOKIR01                  0.019050  476.896113  484.969168 -7.387206e+35\n",
      "AHUTIH                    0.187474  282.531973  325.522689 -1.325243e+35\n",
      "qmof-34facea              0.191163    2.100020    5.586662  2.888341e+35\n",
      "qmof-3503fd0              0.128229   -5.482859  -15.285430  1.169381e+36\n",
      "\n",
      "=== Suitable MOFs for Atmospheric Water Harvesting ===\n",
      "AGARUW: ✅ Suitable for AWH\n"
     ]
    }
   ],
   "source": [
    "# === ASK USER FOR INPUT FILE ===\n",
    "input_file = input(\"Enter the input CSV file name (e.g. test-MOF.csv): \").strip()\n",
    "df_input = pd.read_csv(input_file)\n",
    "df_input['MOF_name'] = df_input['MOF_name'].astype(str).str.strip()\n",
    "df_input.set_index('MOF_name', inplace=True)\n",
    "\n",
    "# EXACT preprocessing order\n",
    "df_input = df_input.apply(pd.to_numeric, errors='coerce')\n",
    "df_input.replace(['#DIV/0!', '#NAME?', 'NaN', 'nan'], np.nan, inplace=True)\n",
    "df_input.fillna(df_input.mean(), inplace=True)\n",
    "\n",
    "# === CLASSIFICATION: PREDICT WATER STABILITY ===\n",
    "available_cls_feats = [f for f in rfa_features if f in df_input.columns]\n",
    "missing_cls_feats = [f for f in rfa_features if f not in df_input.columns]\n",
    "if missing_cls_feats:\n",
    "    print(f\"⚠️ Warning: Missing classification features {missing_cls_feats} will be skipped.\")\n",
    "\n",
    "X_input_cls = df_input[available_cls_feats].copy()\n",
    "X_input_cls = pd.DataFrame(\n",
    "    SimpleImputer(strategy=\"mean\").fit_transform(X_input_cls),\n",
    "    index=df_input.index,\n",
    "    columns=available_cls_feats\n",
    ")\n",
    "\n",
    "for feat in rfa_features:\n",
    "    if feat not in X_input_cls.columns:\n",
    "        X_input_cls[feat] = 0\n",
    "\n",
    "X_input_cls = X_input_cls[rfa_features]\n",
    "X_input_cls = scaler_cls.transform(X_input_cls)\n",
    "\n",
    "model_cls = joblib.load(\"classifier_water_stability.pkl\")\n",
    "df_input['water_stability_prob'] = model_cls.predict_proba(X_input_cls)[:, 1]\n",
    "\n",
    "# === REGRESSION: PREDICT TARGETS IF MISSING ===\n",
    "targets = ['Wselectivity', 'Wup20cm3', 'Wup80cm3']\n",
    "missing_targets = [t for t in targets if t not in df_input.columns]\n",
    "print(f\"Missing target values: {missing_targets}\" if missing_targets else \"✅ All target values provided.\")\n",
    "\n",
    "# descriptors from full dataset\n",
    "headers = list(df_input.columns)\n",
    "descriptors = headers[min(descriptors_indices):max(descriptors_indices) + 1]\n",
    "\n",
    "for target in targets:\n",
    "    model = joblib.load(f\"regressor_{target}.pkl\")\n",
    "    if target not in df_input.columns:\n",
    "        df_input[target] = np.nan\n",
    "\n",
    "    X_pred_reg = df_input[[f for f in descriptors if f in df_input.columns]].copy()\n",
    "    X_pred_reg = X_pred_reg.fillna(X_pred_reg.mean())\n",
    "\n",
    "    missing_mask = df_input[target].isnull()\n",
    "    df_input.loc[missing_mask, target] = model.predict(X_pred_reg[missing_mask])\n",
    "\n",
    "# === EVALUATE RULE-BASED SUITABILITY ===\n",
    "means = df_full[['Wup20cm3', 'Wup80cm3']].mean()\n",
    "stds = df_full[['Wup20cm3', 'Wup80cm3']].std()\n",
    "\n",
    "suitable = df_input[\n",
    "    (df_input['water_stability_prob'] >= 0.75) &\n",
    "    (df_input['Wselectivity'] >= 1000) &\n",
    "    (df_input['Wup20cm3'] >= means['Wup20cm3'] + stds['Wup20cm3']) &\n",
    "    (df_input['Wup80cm3'] >= means['Wup80cm3'] + stds['Wup80cm3'])\n",
    "]\n",
    "\n",
    "# === REPORT RESULTS ===\n",
    "print(\"\\n=== Input MOF Analysis ===\")\n",
    "print(df_input[['water_stability_prob', 'Wup20cm3', 'Wup80cm3', 'Wselectivity']])\n",
    "\n",
    "print(\"\\n=== Suitable MOFs for Atmospheric Water Harvesting ===\")\n",
    "if not suitable.empty:\n",
    "    for mof in suitable.index:\n",
    "        print(f\"{mof}: ✅ Suitable for AWH\")\n",
    "else:\n",
    "    print(\"⚠️ No suitable MOFs found based on the criteria.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
